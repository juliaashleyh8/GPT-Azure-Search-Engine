{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Q&A against Tabular Data from a CSV file"
      ],
      "metadata": {},
      "id": "45b4b5a4-96b0-4935-b890-8eb1c3d678ad"
    },
    {
      "cell_type": "markdown",
      "source": [
        "To really have a Smart Search Engine or Virtual assistant that can answer any question about your corporate documents, this \"engine\" must understand tabular data, aka, sources with tables, rows and columns with numbers. \n",
        "This is a different problem that simply looking for the top most similar results.  The concept of indexing, bringing top results, embedding, doing a cosine semantic search and summarize an answer, doesn't really apply to this problem.\n",
        "We are dealing now with sources with Tables in which each row and column are related to each other, and in order to answer a question, all of the data is needed, not just top results.\n",
        "\n",
        "In this notebook, the goal is to show how to deal with this kind of use cases. To continue with our Covid-19 theme, we will be using an open dataset called [\"Covid Tracking Project\"](https://learn.microsoft.com/en-us/azure/open-datasets/dataset-covid-tracking?tabs=azure-storage). The COVID Tracking Project dataset is a  CSV file that provides the latest numbers on tests, confirmed cases, hospitalizations, and patient outcomes from every US state and territory (they stopped tracking on March 7 2021).\n",
        "\n",
        "Imagine that many documents on a data lake are tabular data, or that your use case is to ask questions in natural language to a LLM model and this model needs to get the context from a CSV file or even a SQL Database in order to answer the question. A GPT Smart Search Engine, must understand how to deal with this sources, understand the data and answer acoordingly."
      ],
      "metadata": {},
      "id": "9697d091-a0fb-4aac-9761-36dbfbebae29"
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from langchain.llms import AzureOpenAI\n",
        "from langchain.chat_models import AzureChatOpenAI\n",
        "from langchain.agents import create_pandas_dataframe_agent\n",
        "from langchain.agents import create_csv_agent\n",
        "\n",
        "# Don't mess with this unless you really know what you are doing\n",
        "AZURE_OPENAI_API_VERSION = \"2023-03-15-preview\"\n",
        "\n",
        "# Change these below with your own services credentials\n",
        "\n",
        "AZURE_OPENAI_ENDPOINT = \"Enter your Azure OpenAI Endpoint ...\"\n",
        "AZURE_OPENAI_KEY = \"Enter your Azure OpenAI Key ...\""
      ],
      "outputs": [],
      "execution_count": 99,
      "metadata": {},
      "id": "4ccab2f5-f8d3-4eb5-b1a7-961388d33d3d"
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the ENV variables that Langchain needs to connect to Azure OpenAI\n",
        "os.environ[\"OPENAI_API_BASE\"] = os.environ[\"AZURE_OPENAI_ENDPOINT\"] = AZURE_OPENAI_ENDPOINT\n",
        "os.environ[\"OPENAI_API_KEY\"] = os.environ[\"AZURE_OPENAI_API_KEY\"] = AZURE_OPENAI_KEY\n",
        "os.environ[\"OPENAI_API_VERSION\"] = os.environ[\"AZURE_OPENAI_API_VERSION\"] = AZURE_OPENAI_API_VERSION"
      ],
      "outputs": [],
      "execution_count": 100,
      "metadata": {},
      "id": "81a497a8-d2f4-40ef-bdd2-389c44c41a2b"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download the dataset and load it into Pandas Dataframe"
      ],
      "metadata": {},
      "id": "dd23c284-a569-4e9f-9c77-62da216be92b"
    },
    {
      "cell_type": "code",
      "source": [
        "file_url = \"https://pandemicdatalake.blob.core.windows.net/public/curated/covid-19/covid_tracking/latest/covid_tracking.csv\"\n",
        "df = pd.read_csv(file_url).fillna(value = 0)\n",
        "print(\"Rows and Columns:\",df.shape)\n",
        "df.head()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Rows and Columns: (22261, 31)\n"
        },
        {
          "output_type": "execute_result",
          "execution_count": 101,
          "data": {
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date</th>\n      <th>state</th>\n      <th>positive</th>\n      <th>negative</th>\n      <th>pending</th>\n      <th>hospitalized_currently</th>\n      <th>hospitalized_cumulative</th>\n      <th>in_icu_currently</th>\n      <th>in_icu_cumulative</th>\n      <th>on_ventilator_currently</th>\n      <th>on_ventilator_cumulative</th>\n      <th>recovered</th>\n      <th>data_quality_grade</th>\n      <th>last_update_et</th>\n      <th>hash</th>\n      <th>date_checked</th>\n      <th>death</th>\n      <th>hospitalized</th>\n      <th>total</th>\n      <th>total_test_results</th>\n      <th>pos_neg</th>\n      <th>fips</th>\n      <th>death_increase</th>\n      <th>hospitalized_increase</th>\n      <th>negative_increase</th>\n      <th>positive_increase</th>\n      <th>total_test_results_increase</th>\n      <th>fips_code</th>\n      <th>iso_subdivision</th>\n      <th>load_time</th>\n      <th>iso_country</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2021-03-07</td>\n      <td>AK</td>\n      <td>56886.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>33.0</td>\n      <td>1293.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2021-03-05 03:59:00</td>\n      <td>dc4bccd4bb885349d7e94d6fed058e285d4be164</td>\n      <td>2021-03-05T03:59:00Z</td>\n      <td>305.0</td>\n      <td>1293.0</td>\n      <td>56886</td>\n      <td>1731628.0</td>\n      <td>56886</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>US-AK</td>\n      <td>2023-04-13 00:05:32</td>\n      <td>US</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2021-03-07</td>\n      <td>AL</td>\n      <td>499819.0</td>\n      <td>1931711.0</td>\n      <td>0.0</td>\n      <td>494.0</td>\n      <td>45976.0</td>\n      <td>0.0</td>\n      <td>2676.0</td>\n      <td>0.0</td>\n      <td>1515.0</td>\n      <td>295690.0</td>\n      <td>0.0</td>\n      <td>2021-03-07 11:00:00</td>\n      <td>997207b430824ea40b8eb8506c19a93e07bc972e</td>\n      <td>2021-03-07T11:00:00Z</td>\n      <td>10148.0</td>\n      <td>45976.0</td>\n      <td>2431530</td>\n      <td>2323788.0</td>\n      <td>2431530</td>\n      <td>1</td>\n      <td>-1</td>\n      <td>0</td>\n      <td>2087</td>\n      <td>408.0</td>\n      <td>2347</td>\n      <td>1</td>\n      <td>US-AL</td>\n      <td>2023-04-13 00:05:32</td>\n      <td>US</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2021-03-07</td>\n      <td>AR</td>\n      <td>324818.0</td>\n      <td>2480716.0</td>\n      <td>0.0</td>\n      <td>335.0</td>\n      <td>14926.0</td>\n      <td>141.0</td>\n      <td>0.0</td>\n      <td>65.0</td>\n      <td>1533.0</td>\n      <td>315517.0</td>\n      <td>0.0</td>\n      <td>2021-03-07 00:00:00</td>\n      <td>50921aeefba3e30d31623aa495b47fb2ecc72fae</td>\n      <td>2021-03-07T00:00:00Z</td>\n      <td>5319.0</td>\n      <td>14926.0</td>\n      <td>2805534</td>\n      <td>2736442.0</td>\n      <td>2805534</td>\n      <td>5</td>\n      <td>22</td>\n      <td>11</td>\n      <td>3267</td>\n      <td>165.0</td>\n      <td>3380</td>\n      <td>5</td>\n      <td>US-AR</td>\n      <td>2023-04-13 00:05:32</td>\n      <td>US</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2021-03-07</td>\n      <td>AS</td>\n      <td>0.0</td>\n      <td>2140.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2020-12-01 00:00:00</td>\n      <td>f77912d0b80d579fbb6202fa1a90554fc4dc1443</td>\n      <td>2020-12-01T00:00:00Z</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2140</td>\n      <td>2140.0</td>\n      <td>2140</td>\n      <td>60</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>60</td>\n      <td>US-AS</td>\n      <td>2023-04-13 00:05:32</td>\n      <td>US</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2021-03-07</td>\n      <td>AZ</td>\n      <td>826454.0</td>\n      <td>3073010.0</td>\n      <td>0.0</td>\n      <td>963.0</td>\n      <td>57907.0</td>\n      <td>273.0</td>\n      <td>0.0</td>\n      <td>143.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2021-03-07 00:00:00</td>\n      <td>0437a7a96f4471666f775e63e86923eb5cbd8cdf</td>\n      <td>2021-03-07T00:00:00Z</td>\n      <td>16328.0</td>\n      <td>57907.0</td>\n      <td>3899464</td>\n      <td>7908105.0</td>\n      <td>3899464</td>\n      <td>4</td>\n      <td>5</td>\n      <td>44</td>\n      <td>13678</td>\n      <td>1335.0</td>\n      <td>45110</td>\n      <td>4</td>\n      <td>US-AZ</td>\n      <td>2023-04-13 00:05:32</td>\n      <td>US</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
            "text/plain": "         date state  positive   negative  pending  hospitalized_currently  \\\n0  2021-03-07    AK   56886.0        0.0      0.0                    33.0   \n1  2021-03-07    AL  499819.0  1931711.0      0.0                   494.0   \n2  2021-03-07    AR  324818.0  2480716.0      0.0                   335.0   \n3  2021-03-07    AS       0.0     2140.0      0.0                     0.0   \n4  2021-03-07    AZ  826454.0  3073010.0      0.0                   963.0   \n\n   hospitalized_cumulative  in_icu_currently  in_icu_cumulative  \\\n0                   1293.0               0.0                0.0   \n1                  45976.0               0.0             2676.0   \n2                  14926.0             141.0                0.0   \n3                      0.0               0.0                0.0   \n4                  57907.0             273.0                0.0   \n\n   on_ventilator_currently  on_ventilator_cumulative  recovered  \\\n0                      2.0                       0.0        0.0   \n1                      0.0                    1515.0   295690.0   \n2                     65.0                    1533.0   315517.0   \n3                      0.0                       0.0        0.0   \n4                    143.0                       0.0        0.0   \n\n   data_quality_grade       last_update_et  \\\n0                 0.0  2021-03-05 03:59:00   \n1                 0.0  2021-03-07 11:00:00   \n2                 0.0  2021-03-07 00:00:00   \n3                 0.0  2020-12-01 00:00:00   \n4                 0.0  2021-03-07 00:00:00   \n\n                                       hash          date_checked    death  \\\n0  dc4bccd4bb885349d7e94d6fed058e285d4be164  2021-03-05T03:59:00Z    305.0   \n1  997207b430824ea40b8eb8506c19a93e07bc972e  2021-03-07T11:00:00Z  10148.0   \n2  50921aeefba3e30d31623aa495b47fb2ecc72fae  2021-03-07T00:00:00Z   5319.0   \n3  f77912d0b80d579fbb6202fa1a90554fc4dc1443  2020-12-01T00:00:00Z      0.0   \n4  0437a7a96f4471666f775e63e86923eb5cbd8cdf  2021-03-07T00:00:00Z  16328.0   \n\n   hospitalized    total  total_test_results  pos_neg  fips  death_increase  \\\n0        1293.0    56886           1731628.0    56886     2               0   \n1       45976.0  2431530           2323788.0  2431530     1              -1   \n2       14926.0  2805534           2736442.0  2805534     5              22   \n3           0.0     2140              2140.0     2140    60               0   \n4       57907.0  3899464           7908105.0  3899464     4               5   \n\n   hospitalized_increase  negative_increase  positive_increase  \\\n0                      0                  0                0.0   \n1                      0               2087              408.0   \n2                     11               3267              165.0   \n3                      0                  0                0.0   \n4                     44              13678             1335.0   \n\n   total_test_results_increase  fips_code iso_subdivision  \\\n0                            0          2           US-AK   \n1                         2347          1           US-AL   \n2                         3380          5           US-AR   \n3                            0         60           US-AS   \n4                        45110          4           US-AZ   \n\n             load_time iso_country  \n0  2023-04-13 00:05:32          US  \n1  2023-04-13 00:05:32          US  \n2  2023-04-13 00:05:32          US  \n3  2023-04-13 00:05:32          US  \n4  2023-04-13 00:05:32          US  "
          },
          "metadata": {}
        }
      ],
      "execution_count": 101,
      "metadata": {},
      "id": "54c0f7eb-0ec2-44aa-b02b-8dbe1b122b28"
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 102,
          "data": {
            "text/plain": "Index(['date', 'state', 'positive', 'negative', 'pending',\n       'hospitalized_currently', 'hospitalized_cumulative', 'in_icu_currently',\n       'in_icu_cumulative', 'on_ventilator_currently',\n       'on_ventilator_cumulative', 'recovered', 'data_quality_grade',\n       'last_update_et', 'hash', 'date_checked', 'death', 'hospitalized',\n       'total', 'total_test_results', 'pos_neg', 'fips', 'death_increase',\n       'hospitalized_increase', 'negative_increase', 'positive_increase',\n       'total_test_results_increase', 'fips_code', 'iso_subdivision',\n       'load_time', 'iso_country'],\n      dtype='object')"
          },
          "metadata": {}
        }
      ],
      "execution_count": 102,
      "metadata": {},
      "id": "d703e877-0a85-43c5-ab35-8ecbe72c44c8"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load our LLM and create our MRKL Agent"
      ],
      "metadata": {},
      "id": "21f25d06-03c3-4f73-bb9a-5a43777d1bf5"
    },
    {
      "cell_type": "markdown",
      "source": [
        "The implementation of Agents is inspired by two papers: the [MRKL Systems](https://arxiv.org/abs/2205.00445) paper (pronounced ‘miracle’ 😉) and the [ReAct](https://arxiv.org/abs/2210.03629) paper.\n",
        "\n",
        "Agents are a way to leverage the ability of LLMs to understand and act on prompts. In essence, an Agent is an LLM that has been given a very clever initial prompt. The prompt tells the LLM to break down the process of answering a complex query into a sequence of steps that are resolved one at a time.\n",
        "\n",
        "Agents become really cool when we combine them with ‘experts’, introduced in the MRKL paper. Simple example: an Agent might not have the inherent capability to reliably perform mathematical calculations by itself. However, we can introduce an expert - in this case a calculator, an expert at mathematical calculations. Now, when we need to perform a calculation, the Agent can call in the expert rather than trying to predict the result itself. This is actually the concept behind [ChatGPT Pluggins](https://openai.com/blog/chatgpt-plugins).\n",
        "\n",
        "In our case, in order to solve the problem \"How do I ask questions to a tabular CSV file\", we need this REACT/MRKL approach, in which we need to instruct the LLM that it needs to use an 'expert/tool' in order to read/load/understand/interact with a CSV tabular file.\n",
        "\n",
        "OpenAI opened the world to a whole new concept. Libraries are being created fast and furious. We will be using [LangChain](https://docs.langchain.com/docs/) as our library to solve this problem, however there are others that we recommend: [HayStack](https://haystack.deepset.ai/) and [Semantic Kernel](https://learn.microsoft.com/en-us/semantic-kernel/whatissk)."
      ],
      "metadata": {},
      "id": "87d4c5dd-8d4b-4a7b-a108-99486582530d"
    },
    {
      "cell_type": "code",
      "source": [
        "# First we load our LLM: GPT-4 (you are welcome to try GPT-3.5-Turbo. \n",
        "# You will see that it does not have the cognitive capabilities to become a smart agent)\n",
        "\n",
        "llm = AzureChatOpenAI(deployment_name=\"gpt-4\", temperature=0.5, max_tokens=500)"
      ],
      "outputs": [],
      "execution_count": 103,
      "metadata": {},
      "id": "46238c2e-2eb4-4fc3-8472-b894380a5063"
    },
    {
      "cell_type": "code",
      "source": [
        "# Now we need our agent and our expert/tool.  \n",
        "# LangChain has created an out-of-the-box agents that we can use to solve our Q&A to CSV tabular data file problem. \n",
        "agent = create_csv_agent(llm, file_url, verbose=True)"
      ],
      "outputs": [],
      "execution_count": 104,
      "metadata": {},
      "id": "0b5a5c3f-41c7-47e9-84d4-6e4c068560d6"
    },
    {
      "cell_type": "code",
      "source": [
        "# Natural Language question (query) + a Suffix to format the answer the way we like\n",
        "preffix = 'First set the pandas display options to show all the columns, then get the column names, then answer the question: '\n",
        "query_str = 'How may patients were hospitalized during July 2020 in Texas and to nationwide?'\n",
        "suffix = '. ALWAYS before giving the Final Answer, try another method. Then reflect on the answers of the two methods you did and ask yourself if it answers correctly the original question. If you are not sure, try another method. \\n If the runs does not give the same result, reflect and try again two more times until you have two runs that have the same result. If you still cannot arrive to a consistent result, say that you are not sure of the answer. But, if you are sure of the correct answer, create a beautiful and thorough response. ALWAYS, as part of your final answer, explain how you got to the answer on a section that starts with: \"\\n\\nExplanation:\\n.\"'"
      ],
      "outputs": [],
      "execution_count": 109,
      "metadata": {},
      "id": "8e0f130f-855f-4844-9987-197f8f9675df"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Enjoy the response and the power of GPT-4 + REACT/MKRL approach"
      ],
      "metadata": {},
      "id": "7d0220e2-9b3f-467e-9843-7a27a09fd39b"
    },
    {
      "cell_type": "code",
      "source": [
        "# We are doing a for loop to retry N times. This is because: \n",
        "# 1) GPT-4 is still in preview and the API is being very throttled and \n",
        "# 2) Because the LLM not always gives the answer on the exact format the agent needs and hence cannot be parsed\n",
        "\n",
        "for i in range(5):\n",
        "    try:\n",
        "        response = agent.run(query_str + suffix) \n",
        "        break\n",
        "    except:\n",
        "        response = \"Error too many failed retries\"\n",
        "        continue  \n",
        "        \n",
        "print(response)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "\n\n\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n\u001b[32;1m\u001b[1;3mThought: First, I need to filter the dataframe to only contain records from Texas and records from July 2020. Then, I'll compute the sum of the 'hospitalized_cumulative' column.\nAction: python_repl_ast\nAction Input: df.info()\u001b[0m<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 22261 entries, 0 to 22260\nData columns (total 31 columns):\n #   Column                       Non-Null Count  Dtype         \n---  ------                       --------------  -----         \n 0   date                         22261 non-null  datetime64[ns]\n 1   state                        22261 non-null  object        \n 2   positive                     22066 non-null  float64       \n 3   negative                     14225 non-null  float64       \n 4   pending                      2479 non-null   float64       \n 5   hospitalized_currently       18584 non-null  float64       \n 6   hospitalized_cumulative      13084 non-null  float64       \n 7   in_icu_currently             12655 non-null  float64       \n 8   in_icu_cumulative            4126 non-null   float64       \n 9   on_ventilator_currently      10017 non-null  float64       \n 10  on_ventilator_cumulative     1290 non-null   float64       \n 11  recovered                    13164 non-null  float64       \n 12  data_quality_grade           0 non-null      float64       \n 13  last_update_et               21608 non-null  object        \n 14  hash                         22261 non-null  object        \n 15  date_checked                 21608 non-null  object        \n 16  death                        21194 non-null  float64       \n 17  hospitalized                 13084 non-null  float64       \n 18  total                        22261 non-null  int64         \n 19  total_test_results           22086 non-null  float64       \n 20  pos_neg                      22261 non-null  int64         \n 21  fips                         22261 non-null  int64         \n 22  death_increase               22261 non-null  int64         \n 23  hospitalized_increase        22261 non-null  int64         \n 24  negative_increase            22261 non-null  int64         \n 25  positive_increase            22232 non-null  float64       \n 26  total_test_results_increase  22261 non-null  int64         \n 27  fips_code                    22261 non-null  int64         \n 28  iso_subdivision              22261 non-null  object        \n 29  load_time                    22261 non-null  object        \n 30  iso_country                  22261 non-null  object        \ndtypes: datetime64[ns](1), float64(15), int64(8), object(7)\nmemory usage: 5.3+ MB\n\nObservation: \u001b[36;1m\u001b[1;3mNone\u001b[0m\nThought:\u001b[32;1m\u001b[1;3mI should filter the dataframe to only have records from Texas and records from July 2020.\nAction: python_repl_ast\nAction Input: tx_july_2020 = df[(df['state'] == 'TX') & (df['date'].str.startswith('2020-07'))]\ntx_july_2020\u001b[0m\nObservation: \u001b[36;1m\u001b[1;3mCan only use .str accessor with string values!\u001b[0m\nThought:\u001b[32;1m\u001b[1;3mI realized that the date column is not in a datetime format. I need to convert the date column into a datetime format before filtering the dataframe.\nAction: python_repl_ast\nAction Input: df['date'] = pd.to_datetime(df['date'])\ndf.info()\u001b[0m<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 22261 entries, 0 to 22260\nData columns (total 31 columns):\n #   Column                       Non-Null Count  Dtype         \n---  ------                       --------------  -----         \n 0   date                         22261 non-null  datetime64[ns]\n 1   state                        22261 non-null  object        \n 2   positive                     22066 non-null  float64       \n 3   negative                     14225 non-null  float64       \n 4   pending                      2479 non-null   float64       \n 5   hospitalized_currently       18584 non-null  float64       \n 6   hospitalized_cumulative      13084 non-null  float64       \n 7   in_icu_currently             12655 non-null  float64       \n 8   in_icu_cumulative            4126 non-null   float64       \n 9   on_ventilator_currently      10017 non-null  float64       \n 10  on_ventilator_cumulative     1290 non-null   float64       \n 11  recovered                    13164 non-null  float64       \n 12  data_quality_grade           0 non-null      float64       \n 13  last_update_et               21608 non-null  object        \n 14  hash                         22261 non-null  object        \n 15  date_checked                 21608 non-null  object        \n 16  death                        21194 non-null  float64       \n 17  hospitalized                 13084 non-null  float64       \n 18  total                        22261 non-null  int64         \n 19  total_test_results           22086 non-null  float64       \n 20  pos_neg                      22261 non-null  int64         \n 21  fips                         22261 non-null  int64         \n 22  death_increase               22261 non-null  int64         \n 23  hospitalized_increase        22261 non-null  int64         \n 24  negative_increase            22261 non-null  int64         \n 25  positive_increase            22232 non-null  float64       \n 26  total_test_results_increase  22261 non-null  int64         \n 27  fips_code                    22261 non-null  int64         \n 28  iso_subdivision              22261 non-null  object        \n 29  load_time                    22261 non-null  object        \n 30  iso_country                  22261 non-null  object        \ndtypes: datetime64[ns](1), float64(15), int64(8), object(7)\nmemory usage: 5.3+ MB\n\nObservation: \u001b[36;1m\u001b[1;3mNone\u001b[0m\nThought:"
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Requests to the Creates a completion for the chat message Operation under Azure OpenAI API version 2023-03-15-preview have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit..\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "\u001b[32;1m\u001b[1;3mNow that the date column is in a datetime format, I can try filtering the dataframe again to only have records from Texas and records from July 2020.\nAction: python_repl_ast\nAction Input: tx_july_2020 = df[(df['state'] == 'TX') & (df['date'].dt.month == 7) & (df['date'].dt.year == 2020)]\ntx_july_2020\u001b[0m\nObservation: \u001b[36;1m\u001b[1;3m            date state  positive  negative  pending  hospitalized_currently  \\\n13190 2020-07-31    TX  420946.0       NaN      NaN                  9336.0   \n13250 2020-07-30    TX  412107.0       NaN      NaN                  9296.0   \n13310 2020-07-29    TX  403307.0       NaN      NaN                  9595.0   \n13370 2020-07-28    TX  394265.0       NaN      NaN                  9593.0   \n13430 2020-07-27    TX  385923.0       NaN      NaN                 10893.0   \n13490 2020-07-26    TX  381656.0       NaN      NaN                 10893.0   \n13550 2020-07-25    TX  375846.0       NaN      NaN                 10893.0   \n13610 2020-07-24    TX  369826.0       NaN      NaN                 10893.0   \n13670 2020-07-23    TX  361125.0       NaN      NaN                 10893.0   \n13730 2020-07-22    TX  351618.0       NaN      NaN                 10893.0   \n13790 2020-07-21    TX  341739.0       NaN      NaN                 10848.0   \n13850 2020-07-20    TX  332434.0       NaN      NaN                 10569.0   \n13910 2020-07-19    TX  325030.0       NaN      NaN                 10592.0   \n13970 2020-07-18    TX  317730.0       NaN      NaN                 10658.0   \n14030 2020-07-17    TX  307572.0       NaN      NaN                 10632.0   \n14090 2020-07-16    TX  292656.0       NaN      NaN                 10457.0   \n14150 2020-07-15    TX  282365.0       NaN      NaN                 10471.0   \n14210 2020-07-14    TX  271574.0       NaN      NaN                 10569.0   \n14270 2020-07-13    TX  264313.0       NaN      NaN                 10405.0   \n14330 2020-07-12    TX  258658.0       NaN      NaN                 10410.0   \n14390 2020-07-11    TX  250462.0       NaN      NaN                 10083.0   \n14450 2020-07-10    TX  240111.0       NaN      NaN                 10002.0   \n14510 2020-07-09    TX  230346.0       NaN      NaN                  9689.0   \n14570 2020-07-08    TX  220564.0       NaN      NaN                  9610.0   \n14630 2020-07-07    TX  210585.0       NaN      NaN                  9286.0   \n14690 2020-07-06    TX  200557.0       NaN      NaN                  8698.0   \n14750 2020-07-05    TX  195239.0       NaN      NaN                  8181.0   \n14810 2020-07-04    TX  191790.0       NaN      NaN                  7890.0   \n14870 2020-07-03    TX  183532.0       NaN      NaN                  7652.0   \n14930 2020-07-02    TX  175977.0       NaN      NaN                  7382.0   \n14990 2020-07-01    TX  168062.0       NaN      NaN                  6904.0   \n\n       hospitalized_cumulative  in_icu_currently  in_icu_cumulative  \\\n13190                      NaN            3115.0                NaN   \n13250                      NaN            3117.0                NaN   \n13310                      NaN            3036.0                NaN   \n13370                      NaN            3087.0                NaN   \n13430                      NaN            3136.0                NaN   \n13490                      NaN            3352.0                NaN   \n13550                      NaN            3209.0                NaN   \n13610                      NaN            3180.0                NaN   \n13670                      NaN            3228.0                NaN   \n13730                      NaN            3160.0                NaN   \n13790                      NaN            3329.0                NaN   \n13850                      NaN            3281.0                NaN   \n13910                      NaN            3197.0                NaN   \n13970                      NaN            3412.0                NaN   \n14030                      NaN            3263.0                NaN   \n14090                      NaN            3216.0                NaN   \n14150                      NaN            3169.0                NaN   \n14210                      NaN            3104.0                NaN   \n14270                      NaN            3144.0                NaN   \n14330                      NaN            3053.0                NaN   \n14390                      NaN            2995.0                NaN   \n14450                      NaN            2913.0                NaN   \n14510                      NaN            2923.0                NaN   \n14570                      NaN            2878.0                NaN   \n14630                      NaN            2730.0                NaN   \n14690                      NaN            2658.0                NaN   \n14750                      NaN            2517.0                NaN   \n14810                      NaN            2449.0                NaN   \n14870                      NaN            2338.0                NaN   \n14930                      NaN            2231.0                NaN   \n14990                      NaN            2155.0                NaN   \n\n       on_ventilator_currently  on_ventilator_cumulative  recovered  \\\n13190                      NaN                       NaN   273191.0   \n13250                      NaN                       NaN   260542.0   \n13310                      NaN                       NaN   251346.0   \n13370                      NaN                       NaN   244449.0   \n13430                      NaN                       NaN   229107.0   \n13490                      NaN                       NaN   229107.0   \n13550                      NaN                       NaN   221510.0   \n13610                      NaN                       NaN   212216.0   \n13670                      NaN                       NaN   203826.0   \n13730                      NaN                       NaN   195315.0   \n13790                      NaN                       NaN   186529.0   \n13850                      NaN                       NaN   177871.0   \n13910                      NaN                       NaN   172936.0   \n13970                      NaN                       NaN   169581.0   \n14030                      NaN                       NaN   162191.0   \n14090                      NaN                       NaN   155937.0   \n14150                      NaN                       NaN   149276.0   \n14210                      NaN                       NaN   142398.0   \n14270                      NaN                       NaN   136419.0   \n14330                      NaN                       NaN   132638.0   \n14390                      NaN                       NaN   127880.0   \n14450                      NaN                       NaN   122996.0   \n14510                      NaN                       NaN   118326.0   \n14570                      NaN                       NaN   113284.0   \n14630                      NaN                       NaN   108485.0   \n14690                      NaN                       NaN   103782.0   \n14750                      NaN                       NaN   100843.0   \n14810                      NaN                       NaN    97430.0   \n14870                      NaN                       NaN    93572.0   \n14930                      NaN                       NaN    90720.0   \n14990                      NaN                       NaN    87556.0   \n\n       data_quality_grade       last_update_et  \\\n13190                 NaN  2020-07-31 17:10:00   \n13250                 NaN  2020-07-30 17:55:00   \n13310                 NaN  2020-07-29 16:50:00   \n13370                 NaN  2020-07-28 17:00:00   \n13430                 NaN  2020-07-27 17:40:00   \n13490                 NaN  2020-07-26 16:50:00   \n13550                 NaN  2020-07-25 16:05:00   \n13610                 NaN  2020-07-24 16:45:00   \n13670                 NaN  2020-07-23 16:15:00   \n13730                 NaN  2020-07-22 17:45:00   \n13790                 NaN  2020-07-21 17:00:00   \n13850                 NaN  2020-07-20 17:25:00   \n13910                 NaN  2020-07-19 17:05:00   \n13970                 NaN  2020-07-18 16:50:00   \n14030                 NaN  2020-07-17 17:15:00   \n14090                 NaN  2020-07-15 17:00:00   \n14150                 NaN  2020-07-15 17:00:00   \n14210                 NaN  2020-07-14 17:25:00   \n14270                 NaN  2020-07-13 16:30:00   \n14330                 NaN  2020-07-12 16:30:00   \n14390                 NaN  2020-07-11 16:35:00   \n14450                 NaN  2020-07-10 16:50:00   \n14510                 NaN  2020-07-09 16:50:00   \n14570                 NaN  2020-07-08 17:45:00   \n14630                 NaN  2020-07-07 16:45:00   \n14690                 NaN  2020-07-06 16:30:00   \n14750                 NaN  2020-07-05 16:15:00   \n14810                 NaN  2020-07-04 16:15:00   \n14870                 NaN  2020-07-03 16:25:00   \n14930                 NaN  2020-07-02 16:40:00   \n14990                 NaN  2020-07-01 16:50:00   \n\n                                           hash          date_checked   death  \\\n13190  2d8850a52d21212607ede95c7f1ac68f352ad772  2020-07-31T17:10:00Z  6569.0   \n13250  cb740d0b1b0ae54eb1e48f53448ffb7217c71583  2020-07-30T17:55:00Z  6274.0   \n13310  bfd7d8a42225a9aa1e8ed4b1a09f2562ddb08220  2020-07-29T16:50:00Z  6190.0   \n13370  0fb337ad902a95aef0ac78e0deb789f21a4eabdf  2020-07-28T17:00:00Z  5877.0   \n13430  47d45d00b2c6379ed5d5ffb5a9f10a2dc542a02c  2020-07-27T17:40:00Z  5713.0   \n13490  c446f6faeab763308d1a5aca05a70560781c41b8  2020-07-26T16:50:00Z  5038.0   \n13550  8dc7c59b2edba6a7d47c0d91700715a0d05380bf  2020-07-25T16:05:00Z  4885.0   \n13610  65d0a704ee2e0ef4283a1e6db0b818371c326587  2020-07-24T16:45:00Z  4717.0   \n13670  ce943a6aa7ad4c8eb00b94684afae61bd7b58c1d  2020-07-23T16:15:00Z  4521.0   \n13730  35c77018fb45b88de0b13dd93d7d4f49d75d4dfc  2020-07-22T17:45:00Z  4348.0   \n13790  7a528f10ca036553338088a573233490180fb912  2020-07-21T17:00:00Z  4151.0   \n13850  465743979dbe17c19a60d2c5751669e0d1b10d5d  2020-07-20T17:25:00Z  4020.0   \n13910  d42e74cf963e5186c42e16921838d5f09279ba01  2020-07-19T17:05:00Z  3958.0   \n13970  e359a6040351db1fcd5a20f7083c5981a5950ebb  2020-07-18T16:50:00Z  3865.0   \n14030  93798e75113e06909cf98f515d8ef750899193de  2020-07-17T17:15:00Z  3735.0   \n14090  93f0546c65b1095d8b148c94b1abbd3ec9a80fa5  2020-07-15T17:00:00Z  3561.0   \n14150  74567dbfc34b9cada6b0639fb1d196883dc2ce03  2020-07-15T17:00:00Z  3432.0   \n14210  ec80ab4fd02a0b88639898d5da0e68d507abc6e7  2020-07-14T17:25:00Z  3322.0   \n14270  c422391d9f45568ba8d9375771ebf82ffc6ec2e5  2020-07-13T16:30:00Z  3235.0   \n14330  dcdd2679805d491ddf5dfa5e22ac0d88249e2b34  2020-07-12T16:30:00Z  3192.0   \n14390  10b246fba63883eb314ad71e9e3bf3954a893331  2020-07-11T16:35:00Z  3112.0   \n14450  08072ce41f3b361d022566e646c8043461c5c448  2020-07-10T16:50:00Z  3013.0   \n14510  139f8b3f41836a1033a75957ff51aa94fda784b6  2020-07-09T16:50:00Z  2918.0   \n14570  9b9f89de84eba93187f6030c1381f46f32d015c2  2020-07-08T17:45:00Z  2813.0   \n14630  246ec78a2986918d4e3a72db81918a19037e2fdf  2020-07-07T16:45:00Z  2715.0   \n14690  c2966aefc05efd22275ededac47da0698c9ec3b8  2020-07-06T16:30:00Z  2655.0   \n14750  97996d13631186cc3f315eafcf5b8da4eece4aed  2020-07-05T16:15:00Z  2637.0   \n14810  c335feb90cf14fcb6b31a7bbaad2fa026d0312f8  2020-07-04T16:15:00Z  2608.0   \n14870  d6815f69f35710a84ee37b0a19c4be664c5686b3  2020-07-03T16:25:00Z  2575.0   \n14930  6a3033800cef817f4d2541bdcb2585a0fee816be  2020-07-02T16:40:00Z  2525.0   \n14990  7a2d6ea9732b032a1659c14af3b29269abe8ad48  2020-07-01T16:50:00Z  2481.0   \n\n       hospitalized   total  total_test_results  pos_neg  fips  \\\n13190           NaN  420946           4378842.0   420946    48   \n13250           NaN  412107           4325751.0   412107    48   \n13310           NaN  403307           4269383.0   403307    48   \n13370           NaN  394265           4214784.0   394265    48   \n13430           NaN  385923           4154831.0   385923    48   \n13490           NaN  381656           4139018.0   381656    48   \n13550           NaN  375846           4116404.0   375846    48   \n13610           NaN  369826           4055305.0   369826    48   \n13670           NaN  361125           3989546.0   361125    48   \n13730           NaN  351618           3927752.0   351618    48   \n13790           NaN  341739           3863650.0   341739    48   \n13850           NaN  332434           3795340.0   332434    48   \n13910           NaN  325030           3774010.0   325030    48   \n13970           NaN  317730           3736854.0   317730    48   \n14030           NaN  307572           3669825.0   307572    48   \n14090           NaN  292656           3593014.0   292656    48   \n14150           NaN  282365           3508722.0   282365    48   \n14210           NaN  271574           3415107.0   271574    48   \n14270           NaN  264313           3327849.0   264313    48   \n14330           NaN  258658           3296431.0   258658    48   \n14390           NaN  250462           3248286.0   250462    48   \n14450           NaN  240111           3161709.0   240111    48   \n14510           NaN  230346           3070305.0   230346    48   \n14570           NaN  220564           2976307.0   220564    48   \n14630           NaN  210585           2884022.0   210585    48   \n14690           NaN  200557           2799179.0   200557    48   \n14750           NaN  195239           2766598.0   195239    48   \n14810           NaN  191790           2745477.0   191790    48   \n14870           NaN  183532           2684650.0   183532    48   \n14930           NaN  175977           2598480.0   175977    48   \n14990           NaN  168062           2513377.0   168062    48   \n\n       death_increase  hospitalized_increase  negative_increase  \\\n13190             295                      0                  0   \n13250              84                      0                  0   \n13310             313                      0                  0   \n13370             164                      0                  0   \n13430             675                      0                  0   \n13490             153                      0                  0   \n13550             168                      0                  0   \n13610             196                      0                  0   \n13670             173                      0                  0   \n13730             197                      0                  0   \n13790             131                      0                  0   \n13850              62                      0                  0   \n13910              93                      0                  0   \n13970             130                      0                  0   \n14030             174                      0                  0   \n14090             129                      0                  0   \n14150             110                      0                  0   \n14210              87                      0                  0   \n14270              43                      0                  0   \n14330              80                      0                  0   \n14390              99                      0                  0   \n14450              95                      0                  0   \n14510             105                      0                  0   \n14570              98                      0                  0   \n14630              60                      0                  0   \n14690              18                      0                  0   \n14750              29                      0                  0   \n14810              33                      0                  0   \n14870              50                      0                  0   \n14930              44                      0                  0   \n14990              57                      0                  0   \n\n       positive_increase  total_test_results_increase  fips_code  \\\n13190             8839.0                        53091         48   \n13250             8800.0                        56368         48   \n13310             9042.0                        54599         48   \n13370             8342.0                        59953         48   \n13430             4267.0                        15813         48   \n13490             5810.0                        22614         48   \n13550             6020.0                        61099         48   \n13610             8701.0                        65759         48   \n13670             9507.0                        61794         48   \n13730             9879.0                        64102         48   \n13790             9305.0                        68310         48   \n13850             7404.0                        21330         48   \n13910             7300.0                        37156         48   \n13970            10158.0                        67029         48   \n14030            14916.0                        76811         48   \n14090            10291.0                        84292         48   \n14150            10791.0                        93615         48   \n14210             7261.0                        87258         48   \n14270             5655.0                        31418         48   \n14330             8196.0                        48145         48   \n14390            10351.0                        86577         48   \n14450             9765.0                        91404         48   \n14510             9782.0                        93998         48   \n14570             9979.0                        92285         48   \n14630            10028.0                        84843         48   \n14690             5318.0                        32581         48   \n14750             3449.0                        21121         48   \n14810             8258.0                        60827         48   \n14870             7555.0                        86170         48   \n14930             7915.0                        85103         48   \n14990             8076.0                        95012         48   \n\n      iso_subdivision            load_time iso_country  \n13190           US-TX  2023-04-13 00:05:32          US  \n13250           US-TX  2023-04-13 00:05:32          US  \n13310           US-TX  2023-04-13 00:05:32          US  \n13370           US-TX  2023-04-13 00:05:32          US  \n13430           US-TX  2023-04-13 00:05:32          US  \n13490           US-TX  2023-04-13 00:05:32          US  \n13550           US-TX  2023-04-13 00:05:32          US  \n13610           US-TX  2023-04-13 00:05:32          US  \n13670           US-TX  2023-04-13 00:05:32          US  \n13730           US-TX  2023-04-13 00:05:32          US  \n13790           US-TX  2023-04-13 00:05:32          US  \n13850           US-TX  2023-04-13 00:05:32          US  \n13910           US-TX  2023-04-13 00:05:32          US  \n13970           US-TX  2023-04-13 00:05:32          US  \n14030           US-TX  2023-04-13 00:05:32          US  \n14090           US-TX  2023-04-13 00:05:32          US  \n14150           US-TX  2023-04-13 00:05:32          US  \n14210           US-TX  2023-04-13 00:05:32          US  \n14270           US-TX  2023-04-13 00:05:32          US  \n14330           US-TX  2023-04-13 00:05:32          US  \n14390           US-TX  2023-04-13 00:05:32          US  \n14450           US-TX  2023-04-13 00:05:32          US  \n14510           US-TX  2023-04-13 00:05:32          US  \n14570           US-TX  2023-04-13 00:05:32          US  \n14630           US-TX  2023-04-13 00:05:32          US  \n14690           US-TX  2023-04-13 00:05:32          US  \n14750           US-TX  2023-04-13 00:05:32          US  \n14810           US-TX  2023-04-13 00:05:32          US  \n14870           US-TX  2023-04-13 00:05:32          US  \n14930           US-TX  2023-04-13 00:05:32          US  \n14990           US-TX  2023-04-13 00:05:32          US  \u001b[0m\nThought:\n\n\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n\u001b[32;1m\u001b[1;3mThought: First, let's filter the dataframe to show only rows from July 2020.\nAction: python_repl_ast\nAction Input: df['date'] = pd.to_datetime(df['date'])\ndf_july_2020 = df[(df['date'] >= '2020-07-01') & (df['date'] <= '2020-07-31')]\nlen(df_july_2020)\u001b[0m\nObservation: \u001b[36;1m\u001b[1;3m1860\u001b[0m\nThought:\u001b[32;1m\u001b[1;3mNow, we have a dataframe with only July's data. Let's filter this dataframe to show only rows for Texas (state == 'TX') and calculate the difference between the highest and lowest hospitalization numbers for Texas (TX).\nAction: python_repl_ast\nAction Input: df_tx_july = df_july_2020[df_july_2020['state'] == 'TX']\ntx_hospitalized_diff = df_tx_july['hospitalized_cumulative'].max() - df_tx_july['hospitalized_cumulative'].min()\ntx_hospitalized_diff\u001b[0m\nObservation: \u001b[36;1m\u001b[1;3mnan\u001b[0m\nThought:\u001b[32;1m\u001b[1;3mIt seems that the `hospitalized_cumulative` column contains NaN values for Texas in July 2020. Let's check if there any non-NaN values in this column for Texas.\nAction: python_repl_ast\nAction Input: df_tx_july['hospitalized_cumulative'].dropna()\u001b[0m\nObservation: \u001b[36;1m\u001b[1;3mSeries([], Name: hospitalized_cumulative, dtype: float64)\u001b[0m\nThought:\u001b[32;1m\u001b[1;3mIt seems that there are no non-NaN values for Texas in the `hospitalized_cumulative` column for July 2020. We cannot determine the number of patients hospitalized in Texas for July 2020 using this data. Now let's calculate the difference between the highest and lowest hospitalization numbers for the entire country (nationwide) in July 2020.\nAction: python_repl_ast\nAction Input: nationwide_hospitalized_diff = df_july_2020['hospitalized_cumulative'].max() - df_july_2020['hospitalized_cumulative'].min()\nnationwide_hospitalized_diff\u001b[0m\nObservation: \u001b[36;1m\u001b[1;3m26901.0\u001b[0m\nThought:\u001b[32;1m\u001b[1;3mWe have calculated the difference between the highest and lowest hospitalization numbers for the entire country (nationwide) in July 2020. Now let's try another method for calculating the nationwide hospitalization numbers for July 2020.\n\nThought: Since the data is cumulative, we can take the difference between the `hospitalized_cumulative` column on the last day of July and the last day of June (2020-07-31 and 2020-06-30 respectively) for the nationwide hospitalization numbers.\nAction: python_repl_ast\nAction Input: df_last_day_july = df[df['date'] == '2020-07-31']\ndf_last_day_june = df[df['date'] == '2020-06-30']\nnationwide_hospitalized_july_second_method = df_last_day_july['hospitalized_cumulative'].sum() - df_last_day_june['hospitalized_cumulative'].sum()\nnationwide_hospitalized_july_second_method\u001b[0m\nObservation: \u001b[36;1m\u001b[1;3m64362.0\u001b[0m\nThought:\u001b[32;1m\u001b[1;3mThe two methods for calculating the nationwide hospitalization numbers for July 2020 give different results (26901 and 64362). This might be due to the fact that some states might have NaN values in the `hospitalized_cumulative` column, which might affect the calculations. In any case, we cannot get a confident answer about the nationwide number of patients hospitalized during July 2020 using this data.\n\nAlso, we couldn't retrieve any information about the number of patients hospitalized in Texas (TX) during July 2020 using this data.\n\nFinal Answer: We cannot determine the number of patients hospitalized during July 2020 in Texas and nationwide with this data.\n\nExplanation:\n\n1. Filtered the dataframe to show only rows from July 2020.\n2. Calculated the difference between the highest and lowest hospitalization numbers for Texas (TX) in July 2020, but the `hospitalized_cumulative` column contained only NaN values for Texas.\n3. Calculated the difference between the highest and lowest hospitalization numbers for the entire country (nationwide) in July 2020 (method 1).\n4. Calculated the nationwide hospitalization numbers for July 2020 by taking the difference between the `hospitalized_cumulative` column on the last day of July and the last day of June (method 2).\n5. The two methods for calculating the nationwide hospitalization numbers for July 2020 give different results, which indicated we cannot get a confident answer using this data.\u001b[0m\n\n\u001b[1m> Finished chain.\u001b[0m\nWe cannot determine the number of patients hospitalized during July 2020 in Texas and nationwide with this data.\n\nExplanation:\n\n1. Filtered the dataframe to show only rows from July 2020.\n2. Calculated the difference between the highest and lowest hospitalization numbers for Texas (TX) in July 2020, but the `hospitalized_cumulative` column contained only NaN values for Texas.\n3. Calculated the difference between the highest and lowest hospitalization numbers for the entire country (nationwide) in July 2020 (method 1).\n4. Calculated the nationwide hospitalization numbers for July 2020 by taking the difference between the `hospitalized_cumulative` column on the last day of July and the last day of June (method 2).\n5. The two methods for calculating the nationwide hospitalization numbers for July 2020 give different results, which indicated we cannot get a confident answer using this data.\n"
        }
      ],
      "execution_count": 110,
      "metadata": {},
      "id": "d6eb9727-036f-4a43-a796-7702183fc57d"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Summary"
      ],
      "metadata": {},
      "id": "073913d5-321b-4c56-9c66-649266cf6280"
    },
    {
      "cell_type": "markdown",
      "source": [
        "So, we just solved our problem on how to ask questions in natural language to our Tabular data hosted on a CSV File.\n",
        "With this approach you can see then that it is NOT necessary to make a dump of a database data into a CSV file and index that on a Search Engine, you don't even need to use the above approach and deal with a CSV data dump file. With the Agents framework, the best engineering decision is to interact directly with the data source API without the need to replicate the data in order to ask questions to it. Remember, GPT-4 can do SQL very well. \n",
        "\n",
        "Just think about this: if GPT-4 can do the above, imagine what GPT-5/6/7/8 will be able to do.\n",
        "\n",
        "This is implemented in the App of this repo as well, where you will be able to upload any tabular CSV you like and ask questions to it"
      ],
      "metadata": {},
      "id": "41108384-c132-45fc-92e4-31dc1bcf00c0"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Reference\n",
        "\n",
        "- https://haystack.deepset.ai/blog/introducing-haystack-agents\n",
        "- https://python.langchain.com/en/latest/modules/agents/agents.html\n",
        "- https://tsmatz.wordpress.com/2023/03/07/react-with-openai-gpt-and-langchain/\n",
        "- https://medium.com/@meghanheintz/intro-to-langchain-llm-templates-and-agents-8793f30f1837"
      ],
      "metadata": {},
      "id": "69e074a0-4f46-40c7-9567-7058ba103f5b"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# NEXT\n",
        "We can see that GPT-4 is powerful and can translate a natural language question into the right steps in python in order to query a CSV data loaded into a pandas dataframe. \n",
        "That's pretty amazing. However the question remains: **Do I need then to dump all the data from my original sources (Databases, ERP Systems, CRM Systems) in order to be searchable by a Smart Search Engine?**\n",
        "\n",
        "The next notebook 5 answers this question by implementing a Question->SQL process and get the information from data in a SQL Database, eliminating the need to dump it out."
      ],
      "metadata": {},
      "id": "88f769ab-db90-48f5-a6b9-60fc0a4a854f"
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {},
      "id": "879aeb79-fc49-4f3b-8a5c-e7758993e2d5"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python310-sdkv2",
      "language": "python",
      "display_name": "Python 3.10 - SDK v2"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.9",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}