{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66ab3cc5-aee4-415a-9391-1e5d37ccaf1d",
   "metadata": {},
   "source": [
    "# Q&A against a SQL Database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "306fc0a9-4044-441d-9ba7-f54f32e6ea9f",
   "metadata": {},
   "source": [
    "Now that we know (from the prior Notebook) how to query tabular data on a CSV file, let's try now to keep the data at is source and ask questions directly to a SQL Database.\n",
    "The goal of this notebook is to demonstrate how a LLM so advanced as GPT-4 can understand a human question and translate that into a SQL query to get the answer. \n",
    "\n",
    "We will be using the Azure SQL Server that you created on the initial deployment. The server should be created on the Resource Group where the Azure Cognitive Search service is located.\n",
    "\n",
    "Let's begin.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c1fb79a3-4856-4721-988c-112813690a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import pyodbc\n",
    "from langchain.llms import AzureOpenAI\n",
    "from langchain.chat_models import AzureChatOpenAI\n",
    "from langchain.agents import create_sql_agent\n",
    "from langchain.agents.agent_toolkits import SQLDatabaseToolkit\n",
    "from langchain.sql_database import SQLDatabase\n",
    "from langchain import SQLDatabaseChain\n",
    "\n",
    "# Don't mess with this unless you really know what you are doing\n",
    "AZURE_OPENAI_API_VERSION = \"2023-03-15-preview\"\n",
    "\n",
    "# Change these below with your own services credentials\n",
    "AZURE_OPENAI_ENDPOINT = \"Enter your Azure OpenAI Endpoint ...\"\n",
    "AZURE_OPENAI_API_KEY = \"Enter your Azure OpenAI Key ...\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "258a6e99-2d4f-4147-b8ee-c64c85296181",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the ENV variables that Langchain needs to connect to Azure OpenAI\n",
    "os.environ[\"OPENAI_API_BASE\"] = os.environ[\"AZURE_OPENAI_ENDPOINT\"] = AZURE_OPENAI_ENDPOINT\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.environ[\"AZURE_OPENAI_API_KEY\"] = AZURE_OPENAI_API_KEY\n",
    "os.environ[\"OPENAI_API_VERSION\"] = os.environ[\"AZURE_OPENAI_API_VERSION\"] = AZURE_OPENAI_API_VERSION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e8e0b32-a6b5-4b1c-943d-e57b737213fa",
   "metadata": {},
   "source": [
    "# Install MS SQL DB driver in your machine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a353df6-0966-4e43-a914-6a2856eb140a",
   "metadata": {},
   "source": [
    "We need the driver installed on this compute in order to talk to the SQL DB, so run the below cell once<br>\n",
    "Reference: https://learn.microsoft.com/en-us/sql/connect/odbc/linux-mac/installing-the-microsoft-odbc-driver-for-sql-server?view=sql-server-ver16&tabs=ubuntu18-install%2Calpine17-install%2Cdebian8-install%2Credhat7-13-install%2Crhel7-offline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "65fbffc7-e149-4eb3-a4db-9f114b06f205",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !sudo ./download_odbc_driver.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e30fa1-877d-4d3b-80b0-e17459c1e4f4",
   "metadata": {},
   "source": [
    "# Load Azure SQL DB with the Covid Tracking CSV Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4352dca-7159-4e41-983d-2c6951cf18db",
   "metadata": {},
   "source": [
    "The Azure SQL Database is currently empty, so we need to fill it up with data. Let's use the same data on the Covid CSV filed we used on the prior Notebook, that way we can compare results and methods. \n",
    "For this, you will need to type below the credentials you used at creation time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "26739d89-e075-4098-ab38-92cccf9f9425",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mssql+pyodbc://dbuser%405htsgeenpq7wq.database.windows.net:Passw0rd.1!!@5htsgeenpq7wq.database.windows.net:1433/SampleDB?driver=ODBC+Driver+18+for+SQL+Server\n",
      "Connection successful!\n",
      "('Microsoft SQL Azure (RTM) - 12.0.2000.8 \\n\\tMar  8 2023 17:58:50 \\n\\tCopyright (C) 2022 Microsoft Corporation\\n',)\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.engine.url import URL\n",
    "\n",
    "# Define the parameters for the database connection\n",
    "server = '<ENTER YOUR VALUE HERE>.database.windows.net'\n",
    "database = '<ENTER YOUR VALUE HERE>'\n",
    "username = '<ENTER YOUR VALUE HERE>'\n",
    "password = '<ENTER YOUR VALUE HERE>'\n",
    "\n",
    "# Don't change this driver variable\n",
    "driver= '{ODBC Driver 18 for SQL Server}'\n",
    "\n",
    "db_config = {\n",
    "    'drivername': 'mssql+pyodbc',\n",
    "    'username': username+'@'+server,\n",
    "    'password': password,\n",
    "    'host': server,\n",
    "    'port': 1433,\n",
    "    'database': database,\n",
    "    'query': {'driver': 'ODBC Driver 18 for SQL Server'}\n",
    "}\n",
    "\n",
    "# Create a URL object for connecting to the database\n",
    "db_url = URL.create(**db_config)\n",
    "\n",
    "# Print the resulting URL string\n",
    "print(db_url)\n",
    "\n",
    "# Connect to the Azure SQL Database using the URL string\n",
    "engine = create_engine(db_url)\n",
    "\n",
    "# Test the connection\n",
    "try:\n",
    "    conn = engine.connect()\n",
    "    print(\"Connection successful!\")\n",
    "    result = engine.execute(\"SELECT @@Version\")\n",
    "    for row in result:\n",
    "        print(row)\n",
    "    conn.close()\n",
    "    \n",
    "except OperationalError:\n",
    "    print(\"Connection failed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "acaf202c-33a1-4105-b506-c26f2080c1d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read CSV file into a pandas dataframe\n",
    "csv_path = \"./data/all-states-history.csv\"\n",
    "df = pd.read_csv(csv_path).fillna(value = 0)\n",
    "\n",
    "# Infer column names and data types\n",
    "column_names = df.columns.tolist()\n",
    "column_types = df.dtypes.to_dict()\n",
    "\n",
    "# Generate SQL statement to create table\n",
    "table_name = 'covidtracking'\n",
    "\n",
    "create_table_sql = f\"CREATE TABLE {table_name} (\"\n",
    "for name, dtype in column_types.items():\n",
    "    if dtype == 'object':\n",
    "        create_table_sql += f\"{name} VARCHAR(255), \"\n",
    "    elif dtype == 'int64':\n",
    "        create_table_sql += f\"{name} INT, \"\n",
    "    elif dtype == 'float64':\n",
    "        create_table_sql += f\"{name} FLOAT, \"\n",
    "    elif dtype == 'bool':\n",
    "        create_table_sql += f\"{name} BIT, \"\n",
    "    elif dtype == 'datetime64[ns]':\n",
    "        create_table_sql += f\"{name} DATETIME, \"\n",
    "create_table_sql = create_table_sql[:-2] + \")\"\n",
    "\n",
    "try:\n",
    "    engine.execute(create_table_sql)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    \n",
    "# Insert data into SQL Database\n",
    "df.to_sql(table_name, con=engine, if_exists='replace', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ad46af-11a4-41a6-94af-15509fd9e16c",
   "metadata": {},
   "source": [
    "# Query with LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7faef3c0-8166-4f3b-a5e3-d30acfd65fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create or LLM Langchain object using GPT-4 deployment\n",
    "llm = AzureChatOpenAI(deployment_name=\"gpt-4\",temperature=0, max_tokens=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6cbe650c-9e0a-4209-9595-de13f2f1ee0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's use a type of Chain made for this type of SQL work.  \n",
    "db = SQLDatabase.from_uri(db_url)\n",
    "db_chain = SQLDatabaseChain(llm=llm, database=db, verbose=True, return_intermediate_steps=True, top_k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ae80c022-415e-40d1-b205-1744a3164d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Natural Language question (query)\n",
    "query_str = 'How may patients were hospitalized during July 2020 in Texas and to nationwide?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6779dc0d-e344-45ca-bd04-fa574e8ccc47",
   "metadata": {},
   "outputs": [],
   "source": [
    "suffix = '. ALWAYS before giving the Final Answer, try another method. Then reflect on the answers of the two methods you did and ask yourself if it answers correctly the original question. If you are not sure, try another method. \\n If the runs does not give the same result, reflect and try again two more times until you have two runs that have the same result. If you still cannot arrive to a consistent result, say that you are not sure of the answer. But, if you are sure of the correct answer, create a beautiful and thorough response. ALWAYS, as part of your final answer, explain how you got to the answer on a section that starts with: \"\\n\\nExplanation:\\n.\"'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "16c2b905-64b8-4fdc-8fc8-7c0274ec6a43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SQLDatabaseChain chain...\u001b[0m\n",
      "How may patients were hospitalized during July 2020 in Texas and to nationwide?. ALWAYS before giving the Final Answer, try another method. Then reflect on the answers of the two methods you did and ask yourself if it answers correctly the original question. If you are not sure, try another method. \n",
      " If the runs does not give the same result, reflect and try again two more times until you have two runs that have the same result. If you still cannot arrive to a consistent result, say that you are not sure of the answer. But, if you are sure of the correct answer, create a beautiful and thorough response. ALWAYS, as part of your final answer, explain how you got to the answer on a section that starts with: \"\n",
      "\n",
      "Explanation:\n",
      ".\" \n",
      "SQLQuery:\u001b[32;1m\u001b[1;3mSELECT state, SUM(hospitalizedIncrease) as total_hospitalized\n",
      "FROM covidtracking\n",
      "WHERE date >= '2020-07-01' AND date <= '2020-07-31' AND (state = 'TX' OR state = 'US')\n",
      "GROUP BY state\n",
      "ORDER BY state\n",
      "\u001b[0m\n",
      "SQLResult: \u001b[33;1m\u001b[1;3m[('TX', 0)]\u001b[0m\n",
      "Answer:\u001b[32;1m\u001b[1;3mIn July 2020, there were 0 patients hospitalized in Texas according to the data available.\n",
      "\n",
      "Explanation: I ran an SQL query to sum the hospitalizedIncrease column for the month of July 2020, filtering by the state of Texas. The result showed that there were 0 patients hospitalized in Texas during that time period.\u001b[0m\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'query': 'How may patients were hospitalized during July 2020 in Texas and to nationwide?. ALWAYS before giving the Final Answer, try another method. Then reflect on the answers of the two methods you did and ask yourself if it answers correctly the original question. If you are not sure, try another method. \\n If the runs does not give the same result, reflect and try again two more times until you have two runs that have the same result. If you still cannot arrive to a consistent result, say that you are not sure of the answer. But, if you are sure of the correct answer, create a beautiful and thorough response. ALWAYS, as part of your final answer, explain how you got to the answer on a section that starts with: \"\\n\\nExplanation:\\n.\"',\n",
       " 'result': 'In July 2020, there were 0 patients hospitalized in Texas according to the data available.\\n\\nExplanation: I ran an SQL query to sum the hospitalizedIncrease column for the month of July 2020, filtering by the state of Texas. The result showed that there were 0 patients hospitalized in Texas during that time period.',\n",
       " 'intermediate_steps': [\"SELECT state, SUM(hospitalizedIncrease) as total_hospitalized\\nFROM covidtracking\\nWHERE date >= '2020-07-01' AND date <= '2020-07-31' AND (state = 'TX' OR state = 'US')\\nGROUP BY state\\nORDER BY state\\n\",\n",
       "  \"[('TX', 0)]\"]}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db_chain(query_str + suffix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95052aba-d0c5-4883-a0b6-70c20e236b6a",
   "metadata": {},
   "source": [
    "### To use or not use Agents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "564867d7-f261-4e4c-99d3-37cf4e5c5000",
   "metadata": {},
   "source": [
    "As you can see above we achieved our goal of Question->SQL without using an Agent, we did it just by using a clever prompt. (You don't see this prompt heere because it is contained in the SQLDatabaseChain class, but you can check it out [HERE](https://github.com/hwchase17/langchain/blob/master/langchain/chains/sql_database/prompt.py)). **So the question is, why do we need an Agent then?**\n",
    "\n",
    "**This is why**: As we explained on the prior Notebook, an agent is a process in which the LLM self-asks about what approach and steps to take, questions the validity of the results and if sure, provides the answer. The SQLDatabaseChain doesn't do all this analysis, but instead tries a one-shot query in order to answer the question, which is good! but not enough for complex questions. That's why it couldn't solve the part about nationwide, it needs multiple steps in order to solve the problem, one query is not enough.\n",
    "Notice that it did't pay atention to the prompt where we explicitly say to try two methods and reflect on the answer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb8b1352-d6d7-4319-a0b8-ae7b9c2fd234",
   "metadata": {},
   "source": [
    "As homework, try to use an agent instead of a chain and get to the same result as Notebook 4 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56cbc405-26e2-471e-9626-2a0df07f5ddc",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7381ea5f-7269-4e1f-8b0c-1e2c04bd84c0",
   "metadata": {},
   "source": [
    "In this notebook, we achieved our goal of Asking a Question in natural language to a dataset located on a SQL Database.  We did this by using purely prompt engineering (Langchain does it for us) and the cognitive power of GPT-4.\n",
    "\n",
    "This process shows why it is NOT necessary to move the data from its original source as long as the source has an API and a common language we can use to interface with. GPT-4 has been trained on the whole public Github corpus, so it can pretty much understand most of the coding and database query languages that exists out there. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 - SDK v2",
   "language": "python",
   "name": "python310-sdkv2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
